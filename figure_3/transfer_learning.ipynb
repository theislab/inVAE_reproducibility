{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icb/ferdinand.kapl/miniconda3/envs/project-inpossible/lib/python3.10/site-packages/scvi/_settings.py:63: UserWarning: Since v1.0.0, scvi-tools no longer uses a random seed by default. Run `scvi.settings.seed = 0` to reproduce results from previous versions.\n",
      "  self.seed = seed\n",
      "/home/icb/ferdinand.kapl/miniconda3/envs/project-inpossible/lib/python3.10/site-packages/scvi/_settings.py:70: UserWarning: Setting `dl_pin_memory_gpu_training` is deprecated in v1.0 and will be removed in v1.1. Please pass in `pin_memory` to the data loaders instead.\n",
      "  self.dl_pin_memory_gpu_training = (\n",
      "/home/icb/ferdinand.kapl/miniconda3/envs/project-inpossible/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import scvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import scvi\n",
    "import scanpy as sc\n",
    "from inVAE import FinVAE\n",
    "import scvi\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from utils import Classifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from scarches.models.scpoli import scPoli\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the directory path\n",
    "directory = '/home/icb/ferdinand.kapl/project-inpossible/outputs/transfer_labeling'\n",
    "\n",
    "# Initialize an empty DataFrame to store the concatenated data\n",
    "concatenated_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for model_name in ['invae', 'scanvi']:\n",
    "    for filename in os.listdir(os.path.join(directory, model_name)):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(directory, model_name, filename)\n",
    "            # Read the CSV file into a DataFrame\n",
    "            df = pd.read_csv(file_path)\n",
    "            df['file_path'] = file_path\n",
    "            # Concatenate the DataFrame to the existing data\n",
    "            concatenated_df = pd.concat([concatenated_df, df])\n",
    "\n",
    "# Print the concatenated DataFrame\n",
    "print(concatenated_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icb/ferdinand.kapl/miniconda3/envs/project-inpossible/lib/python3.10/site-packages/anndata/_core/anndata.py:121: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n",
      "/home/icb/ferdinand.kapl/miniconda3/envs/project-inpossible/lib/python3.10/site-packages/anndata/_core/anndata.py:1830: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/home/icb/ferdinand.kapl/miniconda3/envs/project-inpossible/lib/python3.10/site-packages/anndata/_core/anndata.py:121: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    }
   ],
   "source": [
    "adata = sc.read_h5ad('data/heart_transfer_labeling.h5ad')\n",
    "adata.var_names_make_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    167633\n",
       "test      84801\n",
       "val       18625\n",
       "Name: partition, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs['partition'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.layers['counts'] = adata.layers['counts'].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_train_val = adata[adata.obs['partition'] != 'test']\n",
    "\n",
    "adata_train = adata[adata.obs['partition'] == 'train']\n",
    "adata_val = adata[adata.obs['partition'] == 'val']\n",
    "adata_test = adata[adata.obs['partition'] == 'test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize inVAE emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'checkpoints/invae/model_sep_lin_class_invae_cell_type_1720543205.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing the model and loading weights from given checkpoint...\n",
      "Data loading done!\n"
     ]
    }
   ],
   "source": [
    "# Load Model\n",
    "model = FinVAE.load_model(save_path=checkpoint_path, adata=adata_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating latent representation of passed adata by trying to transfer setup from the adata the model was trained on!\n"
     ]
    }
   ],
   "source": [
    "adata.obsm['X_FinVAE'] = model.get_latent_representation(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(adata, use_rep='X_FinVAE')\n",
    "sc.tl.umap(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obsm['X_FinVAE_umap'] = adata.obsm['X_umap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.set_figure_params(dpi=200,figsize=(6,4),fontsize=10,frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_emb = 'X_FinVAE_umap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.embedding(adata, basis=use_emb, color='predicted_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.embedding(adata, basis=use_emb, color='partition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.embedding(adata, basis=use_emb, color='condition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.embedding(adata, basis=use_emb, color='publication')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize scANVI emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_train_val = adata_train_val.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _eval_model(model, model_name, classifier = None):\n",
    "    # Eval model from args: depending on model\n",
    "    # linear, knn, ...\n",
    "    if classifier is not None:\n",
    "        pred_train = classifier.predict(model.get_latent_representation(adata_train))\n",
    "        pred_val = classifier.predict(model.get_latent_representation(adata_val))\n",
    "        pred_test = classifier.predict(model.get_latent_representation(adata_test))\n",
    "    elif model_name == 'inVAE':\n",
    "        pred_train = model.predict(adata_train, dataset_type='train')\n",
    "        pred_val = model.predict(adata_val, dataset_type='val')\n",
    "        pred_test = model.predict(adata_test, dataset_type='test')\n",
    "    elif model_name == 'scANVI':\n",
    "        pred_train = model.predict(adata_train)\n",
    "        pred_val = model.predict(adata_val)\n",
    "        pred_test = model.predict(adata_test)\n",
    "    else:\n",
    "        print('No prediction method implemented for model', model_name)\n",
    "\n",
    "    label_key = 'predicted_labels'\n",
    "    # Calculate metrics\n",
    "    y_train = adata_train.obs[label_key]\n",
    "    y_val = adata_val.obs[label_key]\n",
    "    y_test = adata_test.obs[label_key]\n",
    "\n",
    "    # Acc\n",
    "    train_acc = (pred_train == y_train).mean()\n",
    "    val_acc = (pred_val == y_val).mean()\n",
    "    test_acc = (pred_test == y_test).mean()\n",
    "\n",
    "    # F1\n",
    "    # Calculate the weighted F1 score\n",
    "    weighted_f1_train = f1_score(y_train, pred_train, average='weighted')\n",
    "    weighted_f1_val = f1_score(y_val, pred_val, average='weighted')\n",
    "    weighted_f1_test = f1_score(y_test, pred_test, average='weighted')\n",
    "\n",
    "    # Calculate the macro F1 score\n",
    "    macro_f1_train = f1_score(y_train, pred_train, average='macro')\n",
    "    macro_f1_val = f1_score(y_val, pred_val, average='macro')\n",
    "    macro_f1_test = f1_score(y_test, pred_test, average='macro')\n",
    "\n",
    "\n",
    "    return {\n",
    "        'train_acc': train_acc,\n",
    "        'val_acc': val_acc,\n",
    "        'test_acc': test_acc,\n",
    "        'weighted_f1_train': weighted_f1_train,\n",
    "        'weighted_f1_val': weighted_f1_val,\n",
    "        'weighted_f1_test': weighted_f1_test,\n",
    "        'macro_f1_train': macro_f1_train,\n",
    "        'macro_fq_val': macro_f1_val,\n",
    "        'macro_f1_test': macro_f1_test\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the checkpoint\n",
    "checkpoint_path_scvi = 'checkpoints/scvi_1720603523/'\n",
    "\n",
    "# Load the scANVI model from the checkpoint\n",
    "model = scvi.model.SCVI.load(checkpoint_path_scvi, adata=adata_train_val, prefix='sep_knn_class_scvi_cell_type_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m File checkpoints/scanvi_1720603523/sep_mlp_class_scanvi_cell_type_model.pt already downloaded             \n"
     ]
    }
   ],
   "source": [
    "# Specify the path to the checkpoint\n",
    "checkpoint_path_scanvi = 'checkpoints/scanvi_1720603523/'\n",
    "\n",
    "# Load the scANVI model from the checkpoint\n",
    "model_scanvi = scvi.model.SCANVI.load(checkpoint_path_scanvi, adata=adata_train_val, prefix='sep_mlp_class_scanvi_cell_type_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over separate classifier checkpoints for scanvi\n",
    "acc_df_scanvi = pd.DataFrame()\n",
    "for filename in os.listdir('checkpoints/scanvi'):\n",
    "    if filename.endswith('1720603523.pt'):\n",
    "        checkpoint_path_class = os.path.join('checkpoints/scanvi', filename)\n",
    "\n",
    "        # Load the classifier model from the checkpoint\n",
    "        classifier = Classifier.load(model_scanvi.get_latent_representation(adata), adata.obs['predicted_labels'], checkpoint_path_class)\n",
    "\n",
    "        # Evaluate the model\n",
    "        eval_dict = _eval_model(model_scanvi, 'scanvi', classifier=classifier)\n",
    "\n",
    "        # Print the evaluation results\n",
    "        class_type = filename.split('_')[2]\n",
    "        print(f'{class_type} classifier evaluation results:')\n",
    "        print(eval_dict)\n",
    "\n",
    "        # Concatenate two pandas dataframes\n",
    "        acc_df_tmp = pd.DataFrame(eval_dict, index=[0])\n",
    "        acc_df_tmp['classifier'] = class_type\n",
    "        acc_df_tmp['model'] = 'scanvi'\n",
    "        acc_df_tmp['file_name'] = filename\n",
    "\n",
    "        acc_df_scanvi = pd.concat([acc_df_scanvi, acc_df_tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over separate classifier checkpoints for scvi\n",
    "acc_df_scvi = pd.DataFrame()\n",
    "for filename in os.listdir('checkpoints/scvi'):\n",
    "    if filename.endswith('.pt'):\n",
    "        checkpoint_path_class = os.path.join('checkpoints/scvi', filename)\n",
    "\n",
    "        # Load the classifier model from the checkpoint\n",
    "        classifier = Classifier.load(model.get_latent_representation(adata), adata.obs['predicted_labels'], checkpoint_path_class)\n",
    "\n",
    "        # Evaluate the model\n",
    "        eval_dict = _eval_model(model, 'scvi', classifier=classifier)\n",
    "\n",
    "        # Print the evaluation results\n",
    "        class_type = filename.split('_')[2]\n",
    "        print(f'{class_type} classifier evaluation results:')\n",
    "        print(eval_dict)\n",
    "\n",
    "        # Concatenate two pandas dataframes\n",
    "        acc_df_tmp = pd.DataFrame(eval_dict, index=[0])\n",
    "        acc_df_tmp['classifier'] = class_type\n",
    "        acc_df_tmp['model'] = 'scvi'\n",
    "        acc_df_tmp['file_name'] = filename\n",
    "\n",
    "        acc_df_scvi = pd.concat([acc_df_scvi, acc_df_tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results for built-in classifier in scANVI\n",
    "# Iterate over classifier checkpoints\n",
    "checkpoint_dir_path = 'outputs/transfer_labeling/scanvi'\n",
    "acc_df_scanvi = pd.DataFrame()\n",
    "for filename in os.listdir(checkpoint_dir_path):\n",
    "    if filename.startswith('scanvi'):\n",
    "        checkpoint_path_class = os.path.join(checkpoint_dir_path, filename)\n",
    "\n",
    "        df_tmp = pd.read_csv(checkpoint_path_class)\n",
    "        df_tmp['file_name'] = filename\n",
    "        df_tmp['classifier'] = filename.split('_')[1]\n",
    "\n",
    "        acc_df_scanvi = pd.concat([acc_df_scanvi, df_tmp])\n",
    "        # condition, predicted_labels, predicted_labels, condition\n",
    "\n",
    "# could extract this from ['config']['data']['label_key']\n",
    "acc_df_scanvi['label_key'] = ['condition', 'predicted_labels', 'predicted_labels', 'condition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all results for separate classifier checkpoints (see concatenated_df above)\n",
    "concatenated_df['model'] = 'invae'\n",
    "\n",
    "acc_df_invae = concatenated_df[['classifier',\n",
    " 'file_name',\n",
    " 'macro_f1_test',\n",
    " 'macro_f1_train',\n",
    " 'macro_fq_val',\n",
    " 'model',\n",
    " 'test_acc',\n",
    " 'train_acc',\n",
    " 'val_acc',\n",
    " 'weighted_f1_test',\n",
    " 'weighted_f1_train',\n",
    " 'weighted_f1_val']]\n",
    "\n",
    "acc_df = pd.concat([acc_df_scvi, acc_df_scanvi, concatenated_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acc_df.drop(columns=['model_name', 'config', 'batch_key'], inplace=True)\n",
    "acc_df.drop(columns=['batch'], inplace=True)\n",
    "\n",
    "acc_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#acc_df.to_csv('outputs/transfer_labeling/separate_classifier_cell_type.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df = pd.read_csv('outputs/transfer_labeling/separate_classifier_cell_type.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_invae_tmp = acc_df.iloc[[0,1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df['model'] = acc_df['model'] + '_' + acc_df['batch_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all single checkpoints for disease classification (manually otherwise need to check 'label_key' in config)\n",
    "df_invae_cond_mlp = pd.read_csv('outputs/transfer_labeling/invae/sep_mlp_class_invae_cell_type_1720626976.csv')\n",
    "df_invae_cond_mlp['classifier'] = 'mlp'\n",
    "\n",
    "df_invae_cond_linear = pd.read_csv('outputs/transfer_labeling/invae/sep_lin_class_invae_cell_type_1720626976.csv')\n",
    "df_invae_cond_linear['classifier'] = 'linear'\n",
    "\n",
    "df_invae_cond_knn = pd.read_csv('outputs/transfer_labeling/invae/sep_knn_class_invae_cell_type_1720626976.csv')\n",
    "df_invae_cond_knn['classifier'] = 'knn'\n",
    "\n",
    "df_invae_cond = pd.concat([df_invae_cond_mlp, df_invae_cond_linear, df_invae_cond_knn])\n",
    "\n",
    "# scanvi disease classification results and cell type\n",
    "df_scanvi_tmp_cond = acc_df_scanvi[acc_df_scanvi['label_key'] == 'condition']\n",
    "df_scanvi_tmp = acc_df_scanvi[acc_df_scanvi['label_key'] == 'predicted_labels']\n",
    "\n",
    "# scpoli disease and cell type classification results\n",
    "df_scpoli_tmp_cond = pd.read_csv('outputs/transfer_labeling/scpoli_disease.csv')\n",
    "df_scpoli_tmp_cond['file_name'] = 'scpoli_disease.csv'\n",
    "\n",
    "df_scpoli_tmp = pd.read_csv('outputs/transfer_labeling/scpoli_cell_type.csv')\n",
    "df_scpoli_tmp['file_name'] = 'scpoli_cell_type.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_classifier(x):\n",
    "    if x == 'lin':\n",
    "        return 'linear'\n",
    "    elif x == 'mlp':\n",
    "        return 'MLP'\n",
    "    elif x == 'knn':\n",
    "        return 'kNN'\n",
    "    \n",
    "acc_df['classifier_nice'] = acc_df['classifier'].(lambda x: rename_classifier(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge them\n",
    "best_cell_type_df = pd.concat([df_invae_tmp, df_scanvi_tmp, df_scpoli_tmp])\n",
    "best_cond_df = pd.concat([df_invae_cond, df_scanvi_tmp_cond, df_scpoli_tmp_cond])\n",
    "\n",
    "# Reset index for selecting rows for plotting\n",
    "best_cond_df.reset_index(drop=True, inplace=True)\n",
    "best_cell_type_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# select best models\n",
    "#best_cond_df = best_cond_df.iloc[[2, 3, 5]]\n",
    "#best_cell_type_df = best_cell_type_df.iloc[[0,1,2]] #[0, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cell_type_df.to_csv('outputs/transfer_labeling/built_in_cell_type_classification.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cond_df.to_csv('outputs/transfer_labeling/built_in_disease_classification.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cell_type_df.loc[[0,1,2], 'model'] = 'invae'\n",
    "best_cell_type_df.loc[[3,4], 'model'] = 'scanvi'\n",
    "best_cell_type_df.at[5, 'model'] = 'scpoli'\n",
    "\n",
    "#best_cell_type_df.at[2, 'classifier'] = 'mlp'\n",
    "\n",
    "#best_cell_type_df['model'] = best_cell_type_df['model'] + '_' + best_cell_type_df['classifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_classifier(x):\n",
    "    if x == 'lin':\n",
    "        return 'linear'\n",
    "    elif x == 'mlp':\n",
    "        return 'MLP'\n",
    "    elif x == 'knn':\n",
    "        return 'kNN'\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "best_cell_type_df['classifier_nice'] = best_cell_type_df['classifier'].apply(lambda x: rename_classifier(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_model(x):\n",
    "    if x == 'invae':\n",
    "        return 'inVAE'\n",
    "    elif x == 'scanvi':\n",
    "        return 'scANVI'\n",
    "    elif x == 'scpoli':\n",
    "        return 'scPoli'\n",
    "    else:\n",
    "        return x\n",
    "#best_cond_df['model_nice'] = best_cond_df['model_name'].apply(lambda x: rename_model(x))    \n",
    "best_cell_type_df['model_nice'] = best_cell_type_df['model'].apply(lambda x: rename_model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique models from the dataframe\n",
    "models = acc_df['model'].unique()\n",
    "\n",
    "# Create a plot for each model\n",
    "for model in models:\n",
    "    # Filter the dataframe for the current model\n",
    "    acc_df_model = acc_df[acc_df['model'] == model]\n",
    "    \n",
    "    # Melt the dataframe for easier plotting\n",
    "    df_melted_model = acc_df_model.melt(id_vars=['classifier_nice'], value_vars=[\n",
    "        'train_acc', 'val_acc', 'test_acc', 'weighted_f1_train', \n",
    "        'weighted_f1_val', 'weighted_f1_test', 'macro_f1_train', \n",
    "        'macro_f1_val', 'macro_f1_test'], var_name='metric', value_name='value')\n",
    "    \n",
    "    # Set the figure size\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    # Create a bar plot\n",
    "    sns.barplot(data=df_melted_model, x='metric', y='value', hue='classifier_nice', dodge=True)\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title(f'Performance Model: {model}')\n",
    "    plt.xlabel('Metric')\n",
    "    plt.ylabel('Value')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend(title='Classifier', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    # Rotate x labels for better readability\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df = best_cond_df\n",
    "\n",
    "# Filter the dataframe for the current model\n",
    "acc_df_model = acc_df\n",
    "\n",
    "# Melt the dataframe for easier plotting\n",
    "#df_melted_model = acc_df_model.melt(id_vars=['model'], value_vars=[\n",
    "#    'train_acc', 'val_acc', 'test_acc', 'weighted_f1_train', \n",
    "#    'weighted_f1_val', 'weighted_f1_test', 'macro_f1_train', \n",
    "#    'macro_f1_val', 'macro_f1_test'], var_name='metric', value_name='value')\n",
    "df_melted_model = acc_df_model.melt(id_vars=['model_nice'], value_vars=[\n",
    "    'test_acc', 'weighted_f1_test', 'macro_f1_test'], var_name='metric', value_name='value')\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Create a bar plot\n",
    "sns.barplot(data=df_melted_model, x='metric', y='value', hue='model_nice', dodge=True)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(f'Disease (control or DCM) classification')\n",
    "plt.xlabel('Metric')\n",
    "plt.ylabel('Value')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(title='Classifier', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Rotate x labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification on unseen disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icb/ferdinand.kapl/miniconda3/envs/project-inpossible/lib/python3.10/site-packages/anndata/_core/anndata.py:121: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n",
      "/home/icb/ferdinand.kapl/miniconda3/envs/project-inpossible/lib/python3.10/site-packages/anndata/_core/anndata.py:1830: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/home/icb/ferdinand.kapl/miniconda3/envs/project-inpossible/lib/python3.10/site-packages/anndata/_core/anndata.py:121: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    }
   ],
   "source": [
    "adata_full = sc.read_h5ad('data/heart_filtered.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chaffin22     137109\n",
       "Reichart22    132767\n",
       "Kanemaru22     53521\n",
       "Name: publication, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_full.obs['publication'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icb/ferdinand.kapl/miniconda3/envs/project-inpossible/lib/python3.10/site-packages/anndata/_core/anndata.py:121: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n",
      "/home/icb/ferdinand.kapl/miniconda3/envs/project-inpossible/lib/python3.10/site-packages/anndata/_core/anndata.py:1830: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/home/icb/ferdinand.kapl/miniconda3/envs/project-inpossible/lib/python3.10/site-packages/anndata/_core/anndata.py:121: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    }
   ],
   "source": [
    "hcm_adata = sc.read_h5ad('data/heart_hcm.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 52270 × 4000\n",
       "    obs: 'donor', 'sex', 'age', 'condition', 'publication', 'kit_10x', 'cell_or_nuclei', 'batch_key', 'cell_type', 'cell_state', 'predicted_labels', 'scrublet_score', 'pred_doublets_per_batch_key', 'pred_scr_thresh_0.2', 'partition'\n",
       "    var: 'index', 'gene_id', 'gene_name', 'gene_biotype', 'gene_seq_start', 'gene_seq_end', 'seq_name', 'seq_strand', 'seq_coord_system', 'description', 'gene_id_version', 'canonical_transcript', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts'\n",
       "    uns: 'age_zero_ten_colors', 'cell_type_colors', 'hvg', 'log1p', 'pred_doublets_per_batch_key_colors'\n",
       "    layers: 'counts'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hcm_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_path = 'checkpoints/scanvi_linear_1720624615/linear_class_model.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_classification_metrics(y_true, y_pred):\n",
    "    acc = np.mean(y_pred == y_true)\n",
    "\n",
    "    # F1\n",
    "    weighted_f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "    # Calculate the macro F1 score\n",
    "    macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    return {\n",
    "        'acc': acc,\n",
    "        'weighted_f1': weighted_f1,\n",
    "        'macro_f1': macro_f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m File checkpoints/scanvi_linear_1720624615/linear_class_model.pt already downloaded                        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData setup                             \n",
      "\u001b[34mINFO    \u001b[0m File checkpoints/scanvi_mlp_1720624639/mlp_class_model.pt already downloaded                              \n",
      "\u001b[34mINFO    \u001b[0m Input AnnData not setup with scvi-tools. attempting to transfer AnnData setup                             \n"
     ]
    }
   ],
   "source": [
    "checkpoints_scanvi_built_in_class = ['checkpoints/scanvi_linear_1720624615/linear_class_model.pt', 'checkpoints/scanvi_mlp_1720624639/mlp_class_model.pt']\n",
    "y_true = hcm_adata.obs['predicted_labels']\n",
    "scanvi_unseen_disease_df = pd.DataFrame()\n",
    "\n",
    "for checkpoint in checkpoints_scanvi_built_in_class:\n",
    "    tmp_dir, tmp_filename = os.path.split(checkpoint)    \n",
    "    model = scvi.model.SCANVI.load(tmp_dir, adata=adata_train_val, prefix='_'.join(tmp_filename.split('_')[:-1]) + '_')\n",
    "\n",
    "    # predict on unseen disease\n",
    "    y_test = model.predict(hcm_adata)\n",
    "\n",
    "    metrics = calculate_classification_metrics(y_true, y_test)\n",
    "\n",
    "    metrics_tmp_df = pd.DataFrame(metrics, index=[0])\n",
    "    metrics_tmp_df['model'] = 'scanvi'\n",
    "    metrics_tmp_df['classifier'] = tmp_filename.split('_')[0]\n",
    "\n",
    "    scanvi_unseen_disease_df = pd.concat([scanvi_unseen_disease_df, metrics_tmp_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_invae = ['checkpoints/invae/model_sep_knn_class_invae_cell_type_1720543205.pt', 'checkpoints/invae/model_sep_lin_class_invae_cell_type_1720543205.pt', 'checkpoints/invae/model_sep_mlp_class_invae_cell_type_1720543205.pt']\n",
    "checkpoint_classifiers_invae = ['checkpoints/invae/class_sep_knn_class_invae_cell_type_1720543205.pt', 'checkpoints/invae/class_sep_lin_class_invae_cell_type_1720543205.pt', 'checkpoints/invae/class_sep_mlp_class_invae_cell_type_1720543205.pt']\n",
    "\n",
    "y_true = hcm_adata.obs['predicted_labels']\n",
    "invae_unseen_disease_df = pd.DataFrame()\n",
    "\n",
    "for chckpt_model, chckpt_class in zip(checkpoints_invae, checkpoint_classifiers_invae):\n",
    "    tmp_dir, tmp_filename = os.path.split(chckpt_model)    \n",
    "    # Load Model\n",
    "    model = FinVAE.load_model(save_path=chckpt_model, adata=adata_train_val, device='cuda')\n",
    "\n",
    "    # Load Classifier\n",
    "    classifier = Classifier.load(model.get_latent_representation(adata_train), adata_train.obs['predicted_labels'], chckpt_class)\n",
    "    \n",
    "    # predict on unseen disease\n",
    "    y_test = classifier.predict(model.get_latent_representation(hcm_adata))\n",
    "\n",
    "    metrics = calculate_classification_metrics(y_true, y_test)\n",
    "\n",
    "    metrics_tmp_df = pd.DataFrame(metrics, index=[0])\n",
    "    metrics_tmp_df['model'] = 'invae'\n",
    "    metrics_tmp_df['classifier'] = tmp_filename.split('_')[2]\n",
    "\n",
    "    invae_unseen_disease_df = pd.concat([invae_unseen_disease_df, metrics_tmp_df])\n",
    "# extract classifiers from filenames\n",
    "class_str = [f.split('_')[2] for f in checkpoints_invae]\n",
    "invae_unseen_disease_df['classifier'] = class_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat all results\n",
    "unseen_disease_df = pd.concat([scanvi_unseen_disease_df, invae_unseen_disease_df])\n",
    "unseen_disease_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.read_csv('outputs/transfer_labeling/built_in_disease_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df['model_nice'] = tmp_df['model_name'] + '_' + tmp_df['classifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df_model = tmp_df\n",
    "\n",
    "# Melt the dataframe for easier plotting\n",
    "#df_melted_model = acc_df_model.melt(id_vars=['model'], value_vars=[\n",
    "#    'train_acc', 'val_acc', 'test_acc', 'weighted_f1_train', \n",
    "#    'weighted_f1_val', 'weighted_f1_test', 'macro_f1_train', \n",
    "#    'macro_f1_val', 'macro_f1_test'], var_name='metric', value_name='value')\n",
    "df_melted_model = acc_df_model.melt(id_vars=['model_nice'], value_vars=[\n",
    "    'acc', 'weighted_f1', 'macro_f1'], var_name='metric', value_name='value')\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Create a bar plot\n",
    "sns.barplot(data=df_melted_model, x='metric', y='value', hue='model_nice', dodge=True)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(f'Cell type classification on unseen disease from new dataset')\n",
    "plt.xlabel('Metric')\n",
    "plt.ylabel('Value')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(title='Classifier', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Rotate x labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df_model = tmp_df\n",
    "\n",
    "# Melt the dataframe for easier plotting\n",
    "#df_melted_model = acc_df_model.melt(id_vars=['model'], value_vars=[\n",
    "#    'train_acc', 'val_acc', 'test_acc', 'weighted_f1_train', \n",
    "#    'weighted_f1_val', 'weighted_f1_test', 'macro_f1_train', \n",
    "#    'macro_f1_val', 'macro_f1_test'], var_name='metric', value_name='value')\n",
    "df_melted_model = acc_df_model.melt(id_vars=['model_nice'], value_vars=[\n",
    "    'test_acc', 'weighted_f1_test', 'macro_f1_test'], var_name='metric', value_name='value')\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Create a bar plot\n",
    "sns.barplot(data=df_melted_model, x='metric', y='value', hue='model_nice', dodge=True)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(f'Disease')\n",
    "plt.xlabel('Metric')\n",
    "plt.ylabel('Value')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(title='Classifier', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Rotate x labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = pd.read_csv('outputs/transfer_labeling/built_in_disease_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_train_val = adata_train_val.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data and label\n",
    "plot_adata = adata_test #hcm_adata\n",
    "label_key = 'condition'\n",
    "plot_only_subset = True\n",
    "\n",
    "y_true = plot_adata.obs[label_key]\n",
    "\n",
    "# Checkpoints\n",
    "\n",
    "## scANVI\n",
    "if label_key == 'predicted_labels':\n",
    "    ### Cell type\n",
    "    checkpoints_scanvi_built_in_class = ['checkpoints/scanvi_linear_1720624615/linear_class_model.pt', 'checkpoints/scanvi_mlp_1720624639/mlp_class_model.pt']\n",
    "elif label_key == 'condition':\n",
    "    ### Disease\n",
    "    checkpoints_scanvi_built_in_class = ['checkpoints/scanvi_linear_1720622826/linear_class_model.pt', 'checkpoints/scanvi_mlp_1720622830/mlp_class_model.pt']\n",
    "\n",
    "## inVAE\n",
    "if label_key == 'predicted_labels':\n",
    "    ### Cell type\n",
    "    checkpoints_invae = ['checkpoints/invae/model_sep_knn_class_invae_cell_type_1720543205.pt', 'checkpoints/invae/model_sep_lin_class_invae_cell_type_1720543205.pt', 'checkpoints/invae/model_sep_mlp_class_invae_cell_type_1720543205.pt']\n",
    "    checkpoint_classifiers_invae = ['checkpoints/invae/class_sep_knn_class_invae_cell_type_1720543205.pt', 'checkpoints/invae/class_sep_lin_class_invae_cell_type_1720543205.pt', 'checkpoints/invae/class_sep_mlp_class_invae_cell_type_1720543205.pt']\n",
    "elif label_key == 'condition':\n",
    "    ### Disease\n",
    "    checkpoints_invae = ['checkpoints/invae/model_sep_knn_class_invae_cell_type_1720626976.pt', 'checkpoints/invae/model_sep_lin_class_invae_cell_type_1720626976.pt', 'checkpoints/invae/model_sep_mlp_class_invae_cell_type_1720626976.pt']\n",
    "    checkpoint_classifiers_invae = ['checkpoints/invae/class_sep_knn_class_invae_cell_type_1720626976.pt', 'checkpoints/invae/class_sep_lin_class_invae_cell_type_1720626976.pt', 'checkpoints/invae/class_sep_mlp_class_invae_cell_type_1720626976.pt']\n",
    "\n",
    "# Sorted labels in decreasing order of frequency\n",
    "unique_labels = y_true.value_counts().sort_values(ascending=False).index.tolist()\n",
    "\n",
    "# For disease only the cell types where disease is expected to have an effect\n",
    "if plot_only_subset and label_key == 'condition':\n",
    "    int_ct = [\n",
    "        'Fibroblast',\n",
    "        'Ventricular Cardiomyocyte',\n",
    "        'Endothelial cell',\n",
    "        'Myeloid',\n",
    "        'Lymphatic Endothelial cell',\n",
    "        'Atrial Cardiomyocyte',\n",
    "    ]\n",
    "else:\n",
    "    int_ct = unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scanvi_df = pd.DataFrame()\n",
    "\n",
    "for checkpoint in checkpoints_scanvi_built_in_class:\n",
    "    tmp_dir, tmp_filename = os.path.split(checkpoint)    \n",
    "    model = scvi.model.SCANVI.load(tmp_dir, adata=adata_train_val, prefix='_'.join(tmp_filename.split('_')[:-1]) + '_')\n",
    "\n",
    "    # predict on unseen disease\n",
    "    y_pred = model.predict(plot_adata)\n",
    "\n",
    "    # Subset for evaluation\n",
    "    y_true_subset = y_true[plot_adata.obs['predicted_labels'].isin(int_ct)]\n",
    "    y_pred_subset = y_pred[plot_adata.obs['predicted_labels'].isin(int_ct)]\n",
    "\n",
    "    # Compute the confusion matrix\n",
    "    cm = confusion_matrix(y_true_subset, y_pred_subset, labels=unique_labels)\n",
    "\n",
    "    # Plot the confusion matrix using Matplotlib\n",
    "    fig, ax = plt.subplots()\n",
    "    ConfusionMatrixDisplay(confusion_matrix=cm).plot(ax=ax)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the confusion matrix using Seaborn\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=unique_labels, yticklabels=unique_labels)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(f\"Confusion Matrix for scANVI with {tmp_filename.split('_')[0]} classifier {f'for only subset' if plot_only_subset else ''}\")\n",
    "    plt.show()\n",
    "\n",
    "    metrics = calculate_classification_metrics(y_true_subset, y_pred_subset)\n",
    "\n",
    "    metrics_tmp_df = pd.DataFrame(metrics, index=[0])\n",
    "    metrics_tmp_df['model'] = 'scanvi'\n",
    "    metrics_tmp_df['classifier'] = tmp_filename.split('_')[0]\n",
    "\n",
    "    scanvi_df = pd.concat([scanvi_df, metrics_tmp_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invae_df = pd.DataFrame()\n",
    "\n",
    "for chckpt_model, chckpt_class in zip(checkpoints_invae, checkpoint_classifiers_invae):\n",
    "    tmp_dir, tmp_filename = os.path.split(chckpt_model)    \n",
    "    # Load Model\n",
    "    model = FinVAE.load_model(save_path=chckpt_model, adata=adata_train_val, device='cuda')\n",
    "\n",
    "    # Load Classifier\n",
    "    classifier = Classifier.load(model.get_latent_representation(adata_train), adata_train.obs[label_key], chckpt_class)\n",
    "    \n",
    "    # predict on unseen disease\n",
    "    y_pred = classifier.predict(model.get_latent_representation(plot_adata))\n",
    "\n",
    "    # Subset for evaluation\n",
    "    y_true_subset = y_true[plot_adata.obs['predicted_labels'].isin(int_ct)]\n",
    "    y_pred_subset = y_pred[plot_adata.obs['predicted_labels'].isin(int_ct)]\n",
    "\n",
    "    # Compute the confusion matrix\n",
    "    cm = confusion_matrix(y_true_subset, y_pred_subset, labels=unique_labels)\n",
    "\n",
    "    # Plot the confusion matrix using Matplotlib\n",
    "    fig, ax = plt.subplots()\n",
    "    ConfusionMatrixDisplay(confusion_matrix=cm).plot(ax=ax)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the confusion matrix using Seaborn\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=unique_labels, yticklabels=unique_labels)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(f\"Confusion Matrix for inVAE with {tmp_filename.split('_')[2]} classifier {f'for only subset' if plot_only_subset else ''}\")\n",
    "    plt.show()\n",
    "\n",
    "    metrics = calculate_classification_metrics(y_true_subset, y_pred_subset)\n",
    "\n",
    "    metrics_tmp_df = pd.DataFrame(metrics, index=[0])\n",
    "    metrics_tmp_df['model'] = 'invae'\n",
    "    metrics_tmp_df['classifier'] = tmp_filename.split('_')[2]\n",
    "\n",
    "    invae_df = pd.concat([invae_df, metrics_tmp_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat results\n",
    "int_ct_disase_df = pd.concat([scanvi_df, invae_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_ct_disase_df['model_nice'] = int_ct_disase_df['model'] + '_' + int_ct_disase_df['classifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df_model = int_ct_disase_df\n",
    "\n",
    "# Melt the dataframe for easier plotting\n",
    "#df_melted_model = acc_df_model.melt(id_vars=['model'], value_vars=[\n",
    "#    'train_acc', 'val_acc', 'test_acc', 'weighted_f1_train', \n",
    "#    'weighted_f1_val', 'weighted_f1_test', 'macro_f1_train', \n",
    "#    'macro_f1_val', 'macro_f1_test'], var_name='metric', value_name='value')\n",
    "df_melted_model = acc_df_model.melt(id_vars=['model_nice'], value_vars=[\n",
    "    'acc', 'weighted_f1', 'macro_f1'], var_name='metric', value_name='value')\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Create a bar plot\n",
    "sns.barplot(data=df_melted_model, x='metric', y='value', hue='model_nice', dodge=True)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title(f'Disease classification on subset of cells')\n",
    "plt.xlabel('Metric')\n",
    "plt.ylabel('Value')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend(title='Classifier', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Rotate x labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
